"""LLM client for generating daily reports using Gemini API - v2.0 Optimized Layout."""

from datetime import datetime
from typing import Optional
from pathlib import Path

from dotenv import load_dotenv
from google import genai
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log,
)

from .utils.logger import setup_logger

logger = setup_logger("generator")

load_dotenv()


class LLMClient:
    """Client for generating daily reports using Gemini API - v2.0 Chief Editor."""

    # v2.0 ä¼˜åŒ–çš„ç³»ç»Ÿæç¤º - æ›´å¥½çš„æ’ç‰ˆå’Œç»“æ„
    SYSTEM_PROMPT = """You are Cloud927, a Senior Solution Architect at Hikvision with a focus on Supply Chain AI.

## Your Mission
Transform raw data into actionable AI intelligence. You're not a news aggregatorâ€”you're an analyst who sees patterns and implications.

## v2.0 Output Format (Optimized Layout)

```markdown
# ğŸ¤– {date} AI Daily Briefing

> **[æ ¸å¿ƒå‘ç°ä¸€å¥è¯]** - One sentence that captures the most critical signal

---

### ğŸ“Š ä¿¡å·å¼ºåº¦æ¦‚è§ˆ
| é¢†åŸŸ | çƒ­åº¦ | é‡è¦å‘ç° |
|------|------|----------|
| [AIæ¨¡å‹] | ğŸ”¥ğŸ”¥ğŸ”¥ | xxx |
| [å¼€æºå·¥å…·] | ğŸ”¥ğŸ”¥ | xxx |
| [äº§å“å‘å¸ƒ] | ğŸ”¥ | xxx |

---

## ğŸš¨ Top Signal (å¿…è¯»)
> **é‡è¦æ€§**: â­â­â­â­â­ | **æ¥æº**: {source}

**[æ ‡é¢˜](url)**
- å…³é”®æ´å¯Ÿ: xxx
- å•†ä¸šå½±å“: xxx

### Cloud927 æ·±åº¦è§£è¯»
> ä»ä¸‰ä¸ªç»´åº¦åˆ†æè¿™ä¸ªä¿¡å·ï¼š

1. **ä¾›åº”é“¾è‡ªåŠ¨åŒ–** ğŸ’
   - xxx

2. **ä¸ªäººAI Agent** ğŸ¤–
   - xxx

3. **Web3è´¢å¯Œæœºä¼š** ğŸª™
   - xxx

---

## ğŸ› ï¸ å·¥ç¨‹å®è·µ (3-5æ¡)
| é¡¹ç›® | è§£å†³çš„é—®é¢˜ | æŠ€æœ¯äº®ç‚¹ |
|------|----------|---------|
| [name](url) | xxx | xxx |

---

## ğŸ”¬ ç ”ç©¶å‰æ²¿ (2-3æ¡)
| è®ºæ–‡/æ¨¡å‹ | æ ¸å¿ƒåˆ›æ–° | åº”ç”¨åœºæ™¯ |
|----------|---------|---------|
| [name](url) | xxx | xxx |

---

## ğŸ†• äº§å“é›·è¾¾ (AIæ–°å“)
| äº§å“ | å®šä½ | çƒ­åº¦ |
|------|------|------|
| [name](url) | xxx | ğŸ‘ğŸ‘ |

---

## ğŸ’¬ ç¤¾åŒºå£°éŸ³ (1-2æ¡)
> **[Redditè®¨è®º](url)**
> æ ¸å¿ƒè§‚ç‚¹: xxx

---

## ğŸ‡¨ğŸ‡³ å›½å†…åŠ¨æ€ (1-2æ¡)
> **[V2EXè®¨è®º](url)**
> å…³é”®è§‚ç‚¹: xxx

---

## ğŸ¯ Cloud927 æ´å¯Ÿ
> **è¶‹åŠ¿åˆ¤æ–­**: [100+ words on the trajectory and implications]

> **è¡ŒåŠ¨å»ºè®®**:
> - [ç«‹å³å¯åš]
> - [çŸ­æœŸè§„åˆ’]
> - [é•¿æœŸè§‚å¯Ÿ]

---
*Generated by Cloud927 v2.0 | Data: HN, GH, HF, PH, Reddit, V2EX*
```

## Critical Rules
1. **Less is More** - Select only 5-8 most impactful items
2. **Structure First** - Use tables for scannability, prose for insights
3. **No Fabricated Links** - Only use provided URLs
4. **Chinese Output** - Simplified Chinese throughout
5. **80+ words minimum** for Closing Insight section

Remember: You're a senior architect. Analyze. Don't just summarize.
"""

    def __init__(self, api_key: Optional[str] = None):
        """Initialize the LLM client.

        Args:
            api_key: Gemini API key. If not provided, loads from environment.
        """
        self.api_key = api_key
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY is required")

    @property
    def client(self):
        """Get or create the Gemini client using google-genai library."""
        if not hasattr(self, "_client"):
            self._client = genai.Client(api_key=self.api_key)
        return self._client

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=60),
        retry=retry_if_exception_type(Exception),
        before_sleep=before_sleep_log(logger, logger.level),
    )
    def generate_report(
        self,
        hn_data: list[dict],
        gh_data: list[dict],
        hf_data: list[dict],
        showhn_data: Optional[list[dict]] = None,
        v2ex_data: Optional[list[dict]] = None,
        ai_news_data: Optional[list[dict]] = None,
        ph_data: Optional[list[dict]] = None,
        reddit_data: Optional[list[dict]] = None,
        date: Optional[datetime] = None,
    ) -> str:
        """Generate a structured daily report from fetched data.

        Args:
            hn_data: List of Hacker News items.
            gh_data: List of GitHub trending items.
            hf_data: List of HuggingFace items.
            showhn_data: List of Show HN items.
            v2ex_data: List of V2EX discussions.
            ai_news_data: List of AI news from official blogs.
            ph_data: List of Product Hunt AI products.
            reddit_data: List of Reddit AI discussions.
            date: Date for the report. Defaults to today.

        Returns:
            Structured markdown report as a string.
        """
        if date is None:
            date = datetime.now()

        date_str = date.strftime("%Y-%m-%d")

        user_prompt = self._build_prompt(
            hn_data=hn_data,
            gh_data=gh_data,
            hf_data=hf_data,
            showhn_data=showhn_data or [],
            v2ex_data=v2ex_data or [],
            ai_news_data=ai_news_data or [],
            ph_data=ph_data or [],
            reddit_data=reddit_data or [],
            date_str=date_str,
        )

        logger.info(f"Generating v2.0 daily report for {date_str}")

        try:
            response = self.client.models.generate_content(
                model="gemini-2.0-flash",
                contents=[user_prompt],
                config={
                    "system_instruction": self.SYSTEM_PROMPT,
                }
            )
            report = response.text.strip()
            logger.info(f"Report generated: {len(report)} chars")
            return report

        except Exception as e:
            logger.error(f"Failed to generate report: {e}")
            raise

    def _format_item(self, item: dict, item_type: str) -> str:
        """Format a single data item."""
        title = item.get("title", item.get("name", "N/A"))
        url = item.get("url", "")
        lines = [f"**æ ‡é¢˜**: {title}", f"**é“¾æ¥**: {url}"]

        if item_type == "hn":
            score = item.get("score", 0)
            time_ago = item.get("time_ago", "")
            excerpt = item.get("excerpt", "")
            lines.extend([f"**åˆ†æ•°**: {score}", f"**æ—¶é—´**: {time_ago}"])
            if excerpt:
                lines.append(f"**æ‘˜è¦**: {excerpt[:400]}")

        elif item_type == "gh":
            desc = item.get("description", "")
            lang = item.get("language", "")
            stars = item.get("stars", 0)
            readme = item.get("readme", "")
            lines.extend([f"**æè¿°**: {desc}", f"**è¯­è¨€**: {lang}", f"**Stars**: {stars}"])
            if readme:
                lines.append(f"**README**: {readme[:400]}")

        elif item_type == "hf":
            abstract = item.get("abstract", "")
            lines.append(f"**æ‘˜è¦**: {abstract[:400]}")

        elif item_type == "showhn":
            readme = item.get("readme", "")
            votes = item.get("score", 0)
            lines.extend([f"**åˆ†æ•°**: {votes}", f"**README**: {readme[:600]}"])

        elif item_type == "v2ex":
            content = item.get("content", "")
            replies = item.get("replies", 0)
            lines.extend([f"**å†…å®¹**: {content[:400]}", f"**å›å¤**: {replies}"])

        elif item_type == "ai_news":
            source = item.get("source", "")
            summary = item.get("summary", "")
            lines.extend([f"**æ¥æº**: {source}", f"**æ€»ç»“**: {summary[:400]}"])

        elif item_type == "ph":
            tagline = item.get("tagline", "")
            votes = item.get("votes", 0)
            lines.extend([f"**æ ‡è¯­**: {tagline}", f"**çƒ­åº¦**: {votes}"])

        elif item_type == "reddit":
            source = item.get("source", "")
            comments = item.get("comments", 0)
            lines.extend([f"**ç¤¾åŒº**: {source}", f"**è¯„è®º**: {comments}"])

        return " | ".join(lines)

    def _build_prompt(
        self,
        hn_data: list[dict],
        gh_data: list[dict],
        hf_data: list[dict],
        showhn_data: list[dict],
        v2ex_data: list[dict],
        ai_news_data: list[dict],
        ph_data: list[dict],
        reddit_data: list[dict],
        date_str: str,
    ) -> str:
        """Build the user prompt with all v2.0 data sources."""

        total_items = len(hn_data) + len(gh_data) + len(hf_data) + len(showhn_data) + len(v2ex_data) + len(ai_news_data) + len(ph_data) + len(reddit_data)

        prompt = f"""# Raw Data for v2.0 Report - {date_str}
**Total Items**: {total_items}

---

## ğŸ”¥ Hacker News Top Stories ({len(hn_data)} items)
"""
        for i, item in enumerate(hn_data[:8], 1):
            prompt += f"### {i}. {self._format_item(item, 'hn')}\n---\n"

        prompt += f"\n## ğŸ¯ Show HN Projects ({len(showhn_data)} items)\n"
        for i, item in enumerate(showhn_data[:3], 1):
            prompt += f"### {i}. {self._format_item(item, 'showhn')}\n---\n"

        prompt += f"\n## â­ GitHub Trending ({len(gh_data)} items)\n"
        for i, item in enumerate(gh_data[:8], 1):
            prompt += f"### {i}. {self._format_item(item, 'gh')}\n---\n"

        prompt += f"\n## ğŸ§  HuggingFace Papers & Models ({len(hf_data)} items)\n"
        for i, item in enumerate(hf_data[:5], 1):
            prompt += f"### {i}. {self._format_item(item, 'hf')}\n---\n"

        prompt += f"\n## ğŸ¤– AI Official News ({len(ai_news_data)} items)\n"
        for i, item in enumerate(ai_news_data[:5], 1):
            prompt += f"### {i}. {self._format_item(item, 'ai_news')}\n---\n"

        prompt += f"\n## ğŸ†• Product Hunt AI ({len(ph_data)} items)\n"
        for i, item in enumerate(ph_data[:5], 1):
            prompt += f"### {i}. {self._format_item(item, 'ph')}\n---\n"

        prompt += f"\n## ğŸ’¬ Reddit AI Discussions ({len(reddit_data)} items)\n"
        for i, item in enumerate(reddit_data[:5], 1):
            prompt += f"### {i}. {self._format_item(item, 'reddit')}\n---\n"

        prompt += f"\n## ğŸ‡¨ğŸ‡³ V2EX Discussions ({len(v2ex_data)} items)\n"
        for i, item in enumerate(v2ex_data[:3], 1):
            prompt += f"### {i}. {self._format_item(item, 'v2ex')}\n---\n"

        prompt += """
---

## ğŸ“ Generation Instructions (IMPORTANT)

Using the v2.0 format, generate a comprehensive AI daily report:

1. **Signal Overview Table** - Categorize findings by domain and urgency
2. **Top Signal** - Select ONE most important item, provide deep 3-pillar analysis
3. **Engineering Practices** - GitHub projects, use table format
4. **Research Frontiers** - HF papers, use table format
5. **Product Radar** - PH launches, use table format
6. **Community Voice** - Top Reddit discussion
7. **China Dynamics** - V2EX insights
8. **Cloud927 Insight** - 100+ words on trajectory + action items

**Selection Criteria**:
- Prioritize AI/ML content over general tech
- Focus on actionable insights
- Balance across all 8 data sources
- Each item must add unique perspective

Write in Simplified Chinese. Use the v2.0 format exactly as specified.
"""

        return prompt
